{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ages and Masses from GALAH Spectra with The Cannon\n",
    "\n",
    "## Part 1: Creating a training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble\n",
    "try:\n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format='retina'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from astropy.table import Table, join\n",
    "from scipy.io.idl import readsav\n",
    "import astropy.io.fits as pyfits\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and join GALAH DR3 and asteroseismic catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in GALAH DR3\n",
    "galah_dr3 = Table.read('../GALAH_DR3/catalogs/GALAH_DR3_all_joined_v2.fits')\n",
    "galah_dr3 = galah_dr3[galah_dr3['dr3_source_id_1'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the asteroseismic data from Zinn et al. (2022)\n",
    "seismic = Table.read('../GALAH_DR4/auxiliary_information/Zinn_Table2_eDR3_xmatch.fits')\n",
    "\n",
    "# Rename some keywords for ease\n",
    "seismic['dr3_source_id_1'] = seismic['source_id']\n",
    "seismic['nu_max'] = seismic['numax_mean']\n",
    "seismic['delta_nu'] = seismic['dnu_mean_corr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-HDU' types <class 'str'> and <class 'str'>, choosing DATE-HDU='2021-10-22T11:56:15' [astropy.utils.metadata]\n"
     ]
    }
   ],
   "source": [
    "# Join GALAH DR3 and the asteroseismic data\n",
    "data = join(galah_dr3, seismic, keys='dr3_source_id_1')\n",
    "\n",
    "# Rename some keywords for ease\n",
    "data['mass'] = data['m_act_bstep']\n",
    "data['age'] = data['age_bstep']\n",
    "\n",
    "# Calculate masses from scaling relations\n",
    "data['mass_astero'] = (data['nu_max']/3076.)**3. * (data['delta_nu']/135.146)**(-4) * (data['teff']/5772)**(3./2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainingset Label Selection\n",
    "\n",
    "We have to do 2 steps, because not all spectra are available publicly for GALAH DR3  \n",
    "So our approach is: select all useful catalog entries, then make sure they all have spectra, then save those as the trainingset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/svenbuder/anaconda3/lib/python3.7/site-packages/astropy/table/column.py:984: RuntimeWarning: invalid value encountered in less\n",
      "  result = getattr(super(), op)(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "989\n"
     ]
    }
   ],
   "source": [
    "# Select a useful preliminary trainingset\n",
    "\n",
    "selection = (\n",
    "    (data['flag_sp'] == 0) & \n",
    "    (data['flag_fe_h'] == 0) & \n",
    "    (data['flag_alpha_fe'] == 0) & \n",
    "    (data['snr_c2_iraf'] > 75) & \n",
    "    (data['teff'] < 5150) & \n",
    "    np.isfinite(data['age']) & \n",
    "    np.isfinite(data['mass']) & \n",
    "    np.isfinite(data['numax_mean']) & \n",
    "    np.isfinite(data['dnu_mean_corr'])\n",
    ")\n",
    "print(len(data['sobject_id'][selection]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create catalog of trainingset\n",
    "preliminary_trainingset = Table()\n",
    "for key in ['sobject_id', 'teff', 'logg','fe_h','alpha_fe','nu_max', 'delta_nu','mass','age','mass_astero','j_m','h_m','ks_m']:\n",
    "    preliminary_trainingset[key] = data[key][selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training set ids, so that we can download them from datacentral.org.au\n",
    "np.savetxt('trainingset_ids.txt',[\", \".join(str(x) for x in preliminary_trainingset['sobject_id'])],fmt='%s')\n",
    "\n",
    "# Now use this list for a bulk download (as described on galah-survey.org) from https://datacentral.org.au/services/download/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the spectra in observation/hermes/*sobejctid*ccd*.fits\n",
    "\n",
    "# Now we check which spectra are missing\n",
    "missing = []\n",
    "\n",
    "for sobject_id in preliminary_trainingset['sobject_id']:\n",
    "    \n",
    "    try:\n",
    "        for ccd in [1,2,3,4]:\n",
    "\n",
    "            fits_file = fits.open('observation/hermes/'+str(sobject_id)+str(ccd)+'.fits')\n",
    "            s = fits_file[4].data\n",
    "\n",
    "            fits_file.close()\n",
    "    except:\n",
    "        missing.append(sobject_id)\n",
    "\n",
    "# Vice versa: Which spectra are available?\n",
    "available = []\n",
    "\n",
    "for sobject_id in preliminary_trainingset['sobject_id']:\n",
    "    if sobject_id not in missing:\n",
    "        available.append(True)\n",
    "    else:\n",
    "        available.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: 'log(cm.s**-2)' did not parse as fits unit: 'log' is not a recognized function [astropy.units.core]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<i>Table masked=True length=875</i>\n",
       "<table id=\"table140441166410320\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>sobject_id</th><th>teff</th><th>logg</th><th>fe_h</th><th>alpha_fe</th><th>nu_max</th><th>delta_nu</th><th>mass</th><th>age</th><th>mass_astero</th><th>j_m</th><th>h_m</th><th>ks_m</th></tr></thead>\n",
       "<thead><tr><th></th><th>K</th><th>log(cm.s**-2)</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th>mag</th><th>mag</th><th>mag</th></tr></thead>\n",
       "<thead><tr><th>int64</th><th>float32</th><th>float32</th><th>float32</th><th>float64</th><th>float32</th><th>float32</th><th>float64</th><th>float64</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th></tr></thead>\n",
       "<tr><td>161006005401094</td><td>4830.7607</td><td>2.364735</td><td>-0.33675337</td><td>0.0800271859202082</td><td>32.167</td><td>4.337</td><td>1.0947040243794466</td><td>6.376832077049619</td><td>0.82558477</td><td>9.194</td><td>8.631</td><td>8.437</td></tr>\n",
       "<tr><td>161006005401076</td><td>4672.3394</td><td>2.3231006</td><td>-0.115608215</td><td>0.049204728181834044</td><td>37.015</td><td>4.196</td><td>1.1224882870355306</td><td>6.593441477004973</td><td>1.3657057</td><td>8.827</td><td>8.198</td><td>8.045</td></tr>\n",
       "<tr><td>140824006301117</td><td>4584.031</td><td>2.1341462</td><td>-0.29746866</td><td>0.06269277936057815</td><td>35.526</td><td>3.929</td><td>1.1185212152459802</td><td>6.93231590248784</td><td>1.5263231</td><td>7.334</td><td>6.715</td><td>6.545</td></tr>\n",
       "<tr><td>140824006301178</td><td>4868.853</td><td>2.492118</td><td>-0.15996265</td><td>0.04322181828260722</td><td>89.557</td><td>7.399</td><td>1.7387946464289636</td><td>2.03368636095098</td><td>2.1281917</td><td>8.63</td><td>8.068</td><td>7.885</td></tr>\n",
       "<tr><td>151111003101006</td><td>4551.1636</td><td>1.9781973</td><td>-0.46227074</td><td>0.08734366140261351</td><td>15.636</td><td>2.479</td><td>1.079395123830893</td><td>7.143227732624391</td><td>0.8123041</td><td>7.72</td><td>7.017</td><td>6.845</td></tr>\n",
       "<tr><td>151111003101382</td><td>4220.5767</td><td>1.9814734</td><td>-0.085291386</td><td>0.16184932646030029</td><td>18.663</td><td>2.508</td><td>1.0569430544009966</td><td>9.877934263582587</td><td>1.1774876</td><td>7.365</td><td>6.646</td><td>6.414</td></tr>\n",
       "<tr><td>160923004201116</td><td>4466.065</td><td>2.2739487</td><td>-0.011614323</td><td>0.10969648273252203</td><td>31.858</td><td>3.906</td><td>1.0849137737086834</td><td>8.455245029001855</td><td>1.0836236</td><td>9.181</td><td>8.548</td><td>8.365</td></tr>\n",
       "<tr><td>160923004201056</td><td>4579.5615</td><td>2.6352112</td><td>-0.0041708946</td><td>0.03420725546068786</td><td>68.692</td><td>6.537</td><td>1.069706517888882</td><td>9.392495598718993</td><td>1.4378201</td><td>9.318</td><td>8.681</td><td>8.513</td></tr>\n",
       "<tr><td>160923004201018</td><td>4581.677</td><td>2.2569964</td><td>-0.4769907</td><td>0.21336342860793286</td><td>22.741</td><td>3.188</td><td>1.0512928771195782</td><td>8.101682672490613</td><td>0.9229036</td><td>8.907</td><td>8.241</td><td>8.112</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>160531004601380</td><td>4449.353</td><td>2.3509438</td><td>0.15931606</td><td>0.12094658901806907</td><td>27.782</td><td>3.781</td><td>1.091609573786168</td><td>9.39768037764901</td><td>0.8139044</td><td>8.795</td><td>8.233</td><td>8.121</td></tr>\n",
       "<tr><td>160531004601333</td><td>4453.8906</td><td>2.3398738</td><td>0.07543707</td><td>0.08035420947492776</td><td>30.576</td><td>4.043</td><td>1.1684257224983041</td><td>7.008469159556075</td><td>0.83119047</td><td>9.059</td><td>8.471</td><td>8.298</td></tr>\n",
       "<tr><td>160531004601193</td><td>4529.0493</td><td>2.5261905</td><td>-0.116009235</td><td>0.13472161199576482</td><td>45.317</td><td>5.332</td><td>1.055315785980756</td><td>9.662487194693922</td><td>0.9172716</td><td>8.456</td><td>7.911</td><td>7.694</td></tr>\n",
       "<tr><td>160531004601191</td><td>4460.015</td><td>2.359446</td><td>0.14239931</td><td>0.12929944596002815</td><td>32.062</td><td>3.843</td><td>1.11412869654816</td><td>8.177726088250175</td><td>1.1764113</td><td>9.274</td><td>8.685</td><td>8.512</td></tr>\n",
       "<tr><td>160531004601198</td><td>5038.199</td><td>2.448899</td><td>-0.67568827</td><td>0.2231717612299529</td><td>46.648</td><td>4.92</td><td>1.1101422311474975</td><td>5.600490296495981</td><td>1.6192572</td><td>9.049</td><td>8.592</td><td>8.468</td></tr>\n",
       "<tr><td>160531004601202</td><td>4562.4536</td><td>2.1294918</td><td>-0.18185711</td><td>0.04475389599561314</td><td>21.675</td><td>2.62</td><td>1.7405038959364403</td><td>1.977459097174957</td><td>1.740741</td><td>7.833</td><td>7.226</td><td>7.063</td></tr>\n",
       "<tr><td>160531004601288</td><td>4583.8857</td><td>2.3433208</td><td>-0.10003185</td><td>0.18575003544149052</td><td>29.885</td><td>3.767</td><td>1.2469971692478445</td><td>5.5701077688833465</td><td>1.0752075</td><td>9.02</td><td>8.463</td><td>8.322</td></tr>\n",
       "<tr><td>160531004601279</td><td>4544.603</td><td>2.400381</td><td>-0.101605415</td><td>0.03118240156868812</td><td>39.79</td><td>4.396</td><td>1.06422741801481</td><td>8.386912136368045</td><td>1.3508257</td><td>8.822</td><td>8.261</td><td>8.101</td></tr>\n",
       "<tr><td>160531004601303</td><td>4461.1484</td><td>2.5823705</td><td>0.029715061</td><td>0.06095940818506916</td><td>52.812</td><td>5.841</td><td>1.0312601501787135</td><td>10.942010014513873</td><td>0.9855604</td><td>8.286</td><td>7.697</td><td>7.545</td></tr>\n",
       "<tr><td>160531005101186</td><td>4707.6685</td><td>2.5291533</td><td>-0.58945465</td><td>0.2436134664935349</td><td>47.151</td><td>5.357</td><td>0.9828901651525378</td><td>9.346798871475587</td><td>1.0746309</td><td>9.128</td><td>8.592</td><td>8.438</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table masked=True length=875>\n",
       "   sobject_id      teff        logg     ...   j_m     h_m     ks_m \n",
       "                    K     log(cm.s**-2) ...   mag     mag     mag  \n",
       "     int64       float32     float32    ... float32 float32 float32\n",
       "--------------- --------- ------------- ... ------- ------- -------\n",
       "161006005401094 4830.7607      2.364735 ...   9.194   8.631   8.437\n",
       "161006005401076 4672.3394     2.3231006 ...   8.827   8.198   8.045\n",
       "140824006301117  4584.031     2.1341462 ...   7.334   6.715   6.545\n",
       "140824006301178  4868.853      2.492118 ...    8.63   8.068   7.885\n",
       "151111003101006 4551.1636     1.9781973 ...    7.72   7.017   6.845\n",
       "151111003101382 4220.5767     1.9814734 ...   7.365   6.646   6.414\n",
       "160923004201116  4466.065     2.2739487 ...   9.181   8.548   8.365\n",
       "160923004201056 4579.5615     2.6352112 ...   9.318   8.681   8.513\n",
       "160923004201018  4581.677     2.2569964 ...   8.907   8.241   8.112\n",
       "            ...       ...           ... ...     ...     ...     ...\n",
       "160531004601380  4449.353     2.3509438 ...   8.795   8.233   8.121\n",
       "160531004601333 4453.8906     2.3398738 ...   9.059   8.471   8.298\n",
       "160531004601193 4529.0493     2.5261905 ...   8.456   7.911   7.694\n",
       "160531004601191  4460.015      2.359446 ...   9.274   8.685   8.512\n",
       "160531004601198  5038.199      2.448899 ...   9.049   8.592   8.468\n",
       "160531004601202 4562.4536     2.1294918 ...   7.833   7.226   7.063\n",
       "160531004601288 4583.8857     2.3433208 ...    9.02   8.463   8.322\n",
       "160531004601279  4544.603      2.400381 ...   8.822   8.261   8.101\n",
       "160531004601303 4461.1484     2.5823705 ...   8.286   7.697   7.545\n",
       "160531005101186 4707.6685     2.5291533 ...   9.128   8.592   8.438"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now save the final trainingset for which we know all spectra are available\n",
    "\n",
    "trainingset = preliminary_trainingset[available]\n",
    "final_trainingset = Table()\n",
    "for key in ['sobject_id', 'teff', 'logg','fe_h','alpha_fe','nu_max', 'delta_nu','mass','age','mass_astero','j_m','h_m','ks_m']:\n",
    "    final_trainingset[key] = trainingset[key]\n",
    "    \n",
    "final_trainingset.write('trainingset.fits',overwrite=True)\n",
    "final_trainingset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainingset Wavelength, Flux, and InverseVariance Preparation\n",
    "\n",
    "Now that we have saved all labels, we need to prepare the wavelengths, fluxes, and inverse variance (ivar) values for the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelength array\n",
    "# For GALAH, we have 4 CCDs\n",
    "\n",
    "cannon_wave = dict()\n",
    "cannon_wave['1']=np.arange(4715.94,4896.00,0.046) # ab lines 4716.3 - 4892.3\n",
    "cannon_wave['2']=np.arange(5653.31,5868.25,0.055) # ab lines 5646.0 - 5867.8\n",
    "cannon_wave['3']=np.arange(6480.52,6733.92,0.064) # ab lines 6481.6 - 6733.4\n",
    "cannon_wave['4']=np.arange(7726.95,7875.55,0.074) # ab lines 7691.2 - 7838.5\n",
    "\n",
    "wavelength_array = np.concatenate(([cannon_wave[key] for key in ['1','2','3','4']]))\n",
    "np.savetxt('wavelength.txt',wavelength_array,fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Cannon needs FLUX and IVAR as inputs\n",
    "# Lets prepare empty arrays and then fill them by looping through the individual training set entries\n",
    "\n",
    "normalized_flux = np.ones((np.shape(final_trainingset)[0],np.shape(wavelength_array)[0]))\n",
    "normalized_ivar = np.ones((np.shape(final_trainingset)[0],np.shape(wavelength_array)[0]))\n",
    "\n",
    "for index, sobject_id in enumerate(final_trainingset['sobject_id']):\n",
    "    \n",
    "    normalised_flux_for_index = []\n",
    "    normalised_ivar_for_index = []\n",
    "    \n",
    "    for ccd in [1,2,3,4]:\n",
    "        \n",
    "        fits_file = fits.open('observation/hermes/'+str(sobject_id)+str(ccd)+'.fits')\n",
    "        wave = fits_file[4].header['CRVAL1'] + fits_file[4].header['CDELT1'] * np.arange(fits_file[4].header['NAXIS1'])\n",
    "        flux = fits_file[4].data\n",
    "        flux_unc = fits_file[4].data * fits_file[1].data\n",
    "        \n",
    "        # Not all spectra are already on the Cannon wavelength grid, so we have to interpolate them onto the Cannon wavelength grid\n",
    "        flux_interpolated = np.interp(cannon_wave[str(ccd)], wave, flux)\n",
    "        flux_unc_interpolated = np.interp(cannon_wave[str(ccd)], wave, flux_unc)\n",
    "        \n",
    "        normalised_flux_for_index.append(flux_interpolated)\n",
    "        normalised_ivar_for_index.append(1./(flux_unc_interpolated**2))\n",
    "        \n",
    "    normalised_flux_for_index = np.concatenate((normalised_flux_for_index))\n",
    "    normalised_ivar_for_index = np.concatenate((normalised_ivar_for_index))\n",
    "    \n",
    "    normalized_flux[index] = normalised_flux_for_index\n",
    "    normalized_ivar[index] = normalised_ivar_for_index\n",
    "    \n",
    "# Now save these 2 entries to a pickle file (more efficient storage)\n",
    "flux_ivar_file_opener = open('trainingset_flux_ivar.pickle','wb')\n",
    "pickle.dump((normalized_flux,normalized_ivar),flux_ivar_file_opener)\n",
    "flux_ivar_file_opener.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
